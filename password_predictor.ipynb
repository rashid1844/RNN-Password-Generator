{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset import and char to index conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:249994, test:4741903\n",
      "char count 2751819\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('Top24Million-WPA-probable-v2.txt', dtype='U',delimiter='\\n', max_rows=5000000) # TODO: check max_rows\n",
    "train, test = train_test_split(data, test_size=0.95, random_state=42)\n",
    "test = set(test)  # to speed up the search\n",
    "text = ' '.join(train) # long string of passwords with space in between for training\n",
    "print(f'train:{len(train)}, test:{len(test)}')\n",
    "print('char count', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Unique Characters: 94\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "chars = sorted(list(set(text)))\n",
    "print('Total Number of Unique Characters:', len(chars))\n",
    "char_idx = dict((c, i) for i, c in enumerate(chars)) # Character to index\n",
    "\n",
    "idx_char = dict((i, c) for i, c in enumerate(chars)) # Index to Character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 917265\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data preprocessing:\n",
    "    1) convert the string into seq_length long strings with (step) stride size\n",
    "    2) convert the input and output to one hot encode\"\"\"\n",
    "\n",
    "seq_length = 25 # Number of characters considered \n",
    "step = 3 # Stide of our window\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Rading the text in terms of sequence of characters\n",
    "# Extract only 'seq_length' characters every time\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sentences.append(text[i: i + seq_length])\n",
    "    # The character just after the sequence is the label\n",
    "    next_chars.append(text[i + seq_length]) \n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "# Initializing Tensor (training data)\n",
    "x = np.zeros((len(sentences), seq_length, len(chars)), dtype=np.bool) \n",
    "# Initializing Output that holds next character (label)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool) \n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        # Populate Tensor Input\n",
    "        x[i, t, char_idx[char]] = 1 \n",
    "    # Populate y with the character just after the sequence\n",
    "    y[i, char_idx[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_hit_rate=[[],[]]\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    \"\"\"After each epoch, compute hit_rate per epoch\"\"\"\n",
    "    hit_rate = pass_hit_rate(model, 5000)\n",
    "    epoch_hit_rate[0].append(epoch)\n",
    "    epoch_hit_rate[1].append(hit_rate)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Perform Temperature Sampling when picking the char from softmax list\"\"\"\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature \n",
    "    exp_preds = np.exp(preds)\n",
    "    # Softmax of predictions\n",
    "    preds = exp_preds / np.sum(exp_preds) \n",
    "    # Sample a single characters, with probabilities defined in `preds`\n",
    "    probas = np.random.multinomial(1, preds, 1) \n",
    "    return np.argmax(probas)\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "def pass_predict(model, char_count=400):\n",
    "    \"\"\"password prediction using the model, repeat for char_count characters\"\"\"\n",
    "    start_index = random.randint(0, len(text) - seq_length - 1)\n",
    "    output_text = ''\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        sentence = text[start_index: start_index + seq_length]\n",
    "        \n",
    "        for i in range(char_count):\n",
    "            x_pred = np.zeros((1, seq_length, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_idx[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            # Generate next character\n",
    "            next_index = sample(preds, diversity) \n",
    "            next_char = idx_char[next_index]\n",
    "            output_text += next_char\n",
    "            # Append character to generated sequence\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "    return output_text.split(' ')  # pass list\n",
    "    \n",
    "    \n",
    "def pass_hit_rate(model, char_count):\n",
    "    \"\"\"Compute hit_rate based on predict password and test list\"\"\"\n",
    "    output = pass_predict(model, char_count)\n",
    "    output = list(filter(lambda x: len(x)>2, output))\n",
    "    hit_rate = 0\n",
    "    for pas in output:\n",
    "        if pas in test:\n",
    "            hit_rate +=1\n",
    "\n",
    "    print('predict size', len(output))\n",
    "    print(f'hit_count: {hit_rate}')\n",
    "    print(f'hit_rate: {np.round(100*hit_rate/len(output), decimals=2)}%')\n",
    "    return hit_rate/len(output)\n",
    "    \n",
    "    \n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "#checkpointer = ModelCheckpoint(filepath='passweights.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Train on 733812 samples, validate on 183453 samples\n",
      "Epoch 1/20\n",
      "733812/733812 [==============================] - 159s 216us/step - loss: 2.7133 - accuracy: 0.2210 - val_loss: 2.5381 - val_accuracy: 0.2541\n",
      "predict size 1905\n",
      "hit_count: 144\n",
      "hit_rate: 7.56%\n",
      "Epoch 2/20\n",
      "733812/733812 [==============================] - 162s 220us/step - loss: 2.4801 - accuracy: 0.2666 - val_loss: 2.4454 - val_accuracy: 0.2773\n",
      "predict size 1929\n",
      "hit_count: 198\n",
      "hit_rate: 10.26%\n",
      "Epoch 3/20\n",
      "733812/733812 [==============================] - 163s 223us/step - loss: 2.3847 - accuracy: 0.2937 - val_loss: 2.3884 - val_accuracy: 0.2947\n",
      "predict size 1728\n",
      "hit_count: 141\n",
      "hit_rate: 8.16%\n",
      "Epoch 4/20\n",
      "109056/733812 [===>..........................] - ETA: 1:55 - loss: 2.2885 - accuracy: 0.3201"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "hidden_size = 512\n",
    "batch = 512\n",
    "epochs=4\n",
    "# Model: LSTM and dense layer withsoftmax to predict char\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_size, input_shape=(seq_length, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax')) \n",
    "\n",
    "optimizer_new = RMSprop() # Optimzes learning rate and adaptive\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_new, metrics=['accuracy']) \n",
    "\n",
    "model_history = model.fit(x, y, batch_size=batch, epochs=epochs,validation_split=0.2, callbacks=[print_callback])\n",
    "model.save_weights('passweights.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# more training\n",
    "#model.load_weights(\"passweights.hdf5\")\n",
    "#model.fit(x, y, batch_size=32, epochs=4)\n",
    "#model.save_weights('passweights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pass_hit_rate(model, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'data{len(data)}_batch{batch}_epochs{epochs}_'\n",
    "#print(model_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title('model accuracy', fontsize=16)\n",
    "plt.ylabel('accuracy', fontsize=14)\n",
    "plt.xlabel('epoch', fontsize=14)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(filename+'model_accuracy.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss', fontsize=16)\n",
    "plt.ylabel('loss', fontsize=14)\n",
    "plt.xlabel('epoch', fontsize=14)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig(filename+'model_loss.pdf', format='pdf')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot hit rate\n",
    "plt.plot(epoch_hit_rate[0], epoch_hit_rate[1])\n",
    "plt.title('model hit rate', fontsize=16)\n",
    "plt.ylabel('hit_rate', fontsize=14)\n",
    "plt.xlabel('epoch', fontsize=14)\n",
    "plt.savefig(filename+'model_hit_rate.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
